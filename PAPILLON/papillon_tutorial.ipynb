{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PAPILLON Tutorial\n",
    "In this notebook, we will walk through how to set up your own PAPILLON pipeline locally with a GPU server step-by-step.\n",
    "\n",
    "### What is PAPILLON?\n",
    "PrivAcy Preservation from Internet-based and Local Language MOdel ENsembles (PAPILLON) is a framework where trusted but weaker models can use untrusted but more powerful models as tools in order to preserve user inference-time privacy.\n",
    "\n",
    "You can refer to the original paper [here](https://arxiv.org/abs/2410.17127) for how we constructed the benchmark for our task.\n",
    "\n",
    "![Overview of the PAPILLON pipeline](figs/1.png)\n",
    "\n",
    "For this tutorial, we will use **GPT-4o-mini** as the untrusted model and **Llama-3.1-8B-Instruct** as the trusted, locally-hosted model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dspy-ai==2.5.41\n",
      "  Downloading dspy_ai-2.5.41-py3-none-any.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: openai in /home/sylvia/anaconda3/envs/papillon/lib/python3.10/site-packages (1.55.0)\n",
      "Requirement already satisfied: pandas in /home/sylvia/.local/lib/python3.10/site-packages (2.2.3)\n",
      "Requirement already satisfied: sglang[all] in /home/sylvia/anaconda3/envs/papillon/lib/python3.10/site-packages (0.3.6)\n",
      "Requirement already satisfied: dspy>=2.5.3 in /home/sylvia/.local/lib/python3.10/site-packages (from dspy-ai==2.5.41) (2.5.32)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/sylvia/.local/lib/python3.10/site-packages (from openai) (4.6.2.post1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/sylvia/anaconda3/envs/papillon/lib/python3.10/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/sylvia/.local/lib/python3.10/site-packages (from openai) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /home/sylvia/.local/lib/python3.10/site-packages (from openai) (0.7.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /home/sylvia/.local/lib/python3.10/site-packages (from openai) (2.9.2)\n",
      "Requirement already satisfied: sniffio in /home/sylvia/.local/lib/python3.10/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /home/sylvia/.local/lib/python3.10/site-packages (from openai) (4.67.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /home/sylvia/.local/lib/python3.10/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /home/sylvia/anaconda3/envs/papillon/lib/python3.10/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/sylvia/.local/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/sylvia/anaconda3/envs/papillon/lib/python3.10/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/sylvia/.local/lib/python3.10/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: requests in /home/sylvia/.local/lib/python3.10/site-packages (from sglang[all]) (2.32.3)\n",
      "Requirement already satisfied: IPython in /home/sylvia/.local/lib/python3.10/site-packages (from sglang[all]) (8.29.0)\n",
      "Requirement already satisfied: idna>=2.8 in /home/sylvia/anaconda3/envs/papillon/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/sylvia/.local/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
      "Requirement already satisfied: backoff in /home/sylvia/.local/lib/python3.10/site-packages (from dspy>=2.5.3->dspy-ai==2.5.41) (2.2.1)\n",
      "Requirement already satisfied: datasets in /home/sylvia/.local/lib/python3.10/site-packages (from dspy>=2.5.3->dspy-ai==2.5.41) (3.1.0)\n",
      "Requirement already satisfied: diskcache in /home/sylvia/.local/lib/python3.10/site-packages (from dspy>=2.5.3->dspy-ai==2.5.41) (5.6.3)\n",
      "Requirement already satisfied: joblib~=1.3 in /home/sylvia/.local/lib/python3.10/site-packages (from dspy>=2.5.3->dspy-ai==2.5.41) (1.4.2)\n",
      "Requirement already satisfied: json-repair in /home/sylvia/.local/lib/python3.10/site-packages (from dspy>=2.5.3->dspy-ai==2.5.41) (0.30.2)\n",
      "Requirement already satisfied: litellm==1.51.0 in /home/sylvia/anaconda3/envs/papillon/lib/python3.10/site-packages (from dspy>=2.5.3->dspy-ai==2.5.41) (1.51.0)\n",
      "Requirement already satisfied: magicattr~=0.1.6 in /home/sylvia/.local/lib/python3.10/site-packages (from dspy>=2.5.3->dspy-ai==2.5.41) (0.1.6)\n",
      "Requirement already satisfied: optuna in /home/sylvia/.local/lib/python3.10/site-packages (from dspy>=2.5.3->dspy-ai==2.5.41) (4.1.0)\n",
      "Requirement already satisfied: regex in /home/sylvia/.local/lib/python3.10/site-packages (from dspy>=2.5.3->dspy-ai==2.5.41) (2024.11.6)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in /home/sylvia/.local/lib/python3.10/site-packages (from dspy>=2.5.3->dspy-ai==2.5.41) (9.0.0)\n",
      "Requirement already satisfied: ujson in /home/sylvia/.local/lib/python3.10/site-packages (from dspy>=2.5.3->dspy-ai==2.5.41) (5.10.0)\n",
      "Requirement already satisfied: asyncer==0.0.8 in /home/sylvia/.local/lib/python3.10/site-packages (from dspy>=2.5.3->dspy-ai==2.5.41) (0.0.8)\n",
      "Requirement already satisfied: aiohttp in /home/sylvia/.local/lib/python3.10/site-packages (from litellm==1.51.0->dspy>=2.5.3->dspy-ai==2.5.41) (3.11.6)\n",
      "Requirement already satisfied: click in /home/sylvia/anaconda3/envs/papillon/lib/python3.10/site-packages (from litellm==1.51.0->dspy>=2.5.3->dspy-ai==2.5.41) (8.1.7)\n",
      "Requirement already satisfied: importlib-metadata>=6.8.0 in /home/sylvia/.local/lib/python3.10/site-packages (from litellm==1.51.0->dspy>=2.5.3->dspy-ai==2.5.41) (8.5.0)\n",
      "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in /home/sylvia/.local/lib/python3.10/site-packages (from litellm==1.51.0->dspy>=2.5.3->dspy-ai==2.5.41) (3.1.4)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in /home/sylvia/.local/lib/python3.10/site-packages (from litellm==1.51.0->dspy>=2.5.3->dspy-ai==2.5.41) (4.23.0)\n",
      "Requirement already satisfied: python-dotenv>=0.2.0 in /home/sylvia/.local/lib/python3.10/site-packages (from litellm==1.51.0->dspy>=2.5.3->dspy-ai==2.5.41) (1.0.1)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in /home/sylvia/anaconda3/envs/papillon/lib/python3.10/site-packages (from litellm==1.51.0->dspy>=2.5.3->dspy-ai==2.5.41) (0.7.0)\n",
      "Requirement already satisfied: tokenizers in /home/sylvia/.local/lib/python3.10/site-packages (from litellm==1.51.0->dspy>=2.5.3->dspy-ai==2.5.41) (0.20.3)\n",
      "Requirement already satisfied: certifi in /home/sylvia/anaconda3/envs/papillon/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /home/sylvia/.local/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/sylvia/.local/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/sylvia/.local/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /home/sylvia/.local/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
      "Requirement already satisfied: six>=1.5 in /home/sylvia/anaconda3/envs/papillon/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/sylvia/.local/lib/python3.10/site-packages (from requests->sglang[all]) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/sylvia/anaconda3/envs/papillon/lib/python3.10/site-packages (from requests->sglang[all]) (2.2.3)\n",
      "Requirement already satisfied: decorator in /home/sylvia/.local/lib/python3.10/site-packages (from IPython->sglang[all]) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/sylvia/.local/lib/python3.10/site-packages (from IPython->sglang[all]) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /home/sylvia/.local/lib/python3.10/site-packages (from IPython->sglang[all]) (0.1.7)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /home/sylvia/.local/lib/python3.10/site-packages (from IPython->sglang[all]) (3.0.48)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/sylvia/.local/lib/python3.10/site-packages (from IPython->sglang[all]) (2.18.0)\n",
      "Requirement already satisfied: stack-data in /home/sylvia/.local/lib/python3.10/site-packages (from IPython->sglang[all]) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in /home/sylvia/.local/lib/python3.10/site-packages (from IPython->sglang[all]) (5.14.3)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/sylvia/anaconda3/envs/papillon/lib/python3.10/site-packages (from IPython->sglang[all]) (4.9.0)\n",
      "Collecting anthropic>=0.20.0 (from sglang[all])\n",
      "  Downloading anthropic-0.40.0-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: torch in /home/sylvia/.local/lib/python3.10/site-packages (from sglang[all]) (2.5.1)\n",
      "Requirement already satisfied: vllm>=0.6.3.post1 in /home/sylvia/anaconda3/envs/papillon/lib/python3.10/site-packages (from sglang[all]) (0.6.4.post1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /home/sylvia/.local/lib/python3.10/site-packages (from jedi>=0.16->IPython->sglang[all]) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/sylvia/anaconda3/envs/papillon/lib/python3.10/site-packages (from pexpect>4.3->IPython->sglang[all]) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/sylvia/.local/lib/python3.10/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->IPython->sglang[all]) (0.2.13)\n",
      "Requirement already satisfied: psutil in /home/sylvia/anaconda3/envs/papillon/lib/python3.10/site-packages (from vllm>=0.6.3.post1->sglang[all]) (6.1.0)\n",
      "Requirement already satisfied: sentencepiece in /home/sylvia/anaconda3/envs/papillon/lib/python3.10/site-packages (from vllm>=0.6.3.post1->sglang[all]) (0.2.0)\n",
      "Requirement already satisfied: py-cpuinfo in /home/sylvia/anaconda3/envs/papillon/lib/python3.10/site-packages (from vllm>=0.6.3.post1->sglang[all]) (9.0.0)\n",
      "Requirement already satisfied: transformers>=4.45.2 in /home/sylvia/anaconda3/envs/papillon/lib/python3.10/site-packages (from vllm>=0.6.3.post1->sglang[all]) (4.46.3)\n",
      "Requirement already satisfied: protobuf in /home/sylvia/anaconda3/envs/papillon/lib/python3.10/site-packages (from vllm>=0.6.3.post1->sglang[all]) (5.28.3)\n",
      "Requirement already satisfied: uvicorn[standard] in /home/sylvia/anaconda3/envs/papillon/lib/python3.10/site-packages (from vllm>=0.6.3.post1->sglang[all]) (0.32.1)\n",
      "Requirement already satisfied: pillow in /home/sylvia/anaconda3/envs/papillon/lib/python3.10/site-packages (from vllm>=0.6.3.post1->sglang[all]) (10.4.0)\n",
      "Requirement already satisfied: prometheus-client>=0.18.0 in /home/sylvia/anaconda3/envs/papillon/lib/python3.10/site-packages (from vllm>=0.6.3.post1->sglang[all]) (0.21.0)\n",
      "Requirement already satisfied: prometheus-fastapi-instrumentator>=7.0.0 in /home/sylvia/anaconda3/envs/papillon/lib/python3.10/site-packages (from vllm>=0.6.3.post1->sglang[all]) (7.0.0)\n",
      "Requirement already satisfied: lm-format-enforcer<0.11,>=0.10.9 in /home/sylvia/anaconda3/envs/papillon/lib/python3.10/site-packages (from vllm>=0.6.3.post1->sglang[all]) (0.10.9)\n",
      "Requirement already satisfied: outlines<0.1,>=0.0.43 in /home/sylvia/anaconda3/envs/papillon/lib/python3.10/site-packages (from vllm>=0.6.3.post1->sglang[all]) (0.0.46)\n",
      "Requirement already satisfied: filelock>=3.10.4 in /home/sylvia/.local/lib/python3.10/site-packages (from vllm>=0.6.3.post1->sglang[all]) (3.16.1)\n",
      "Requirement already satisfied: partial-json-parser in /home/sylvia/anaconda3/envs/papillon/lib/python3.10/site-packages (from vllm>=0.6.3.post1->sglang[all]) (0.2.1.1.post4)\n",
      "Requirement already satisfied: pyzmq in /home/sylvia/anaconda3/envs/papillon/lib/python3.10/site-packages (from vllm>=0.6.3.post1->sglang[all]) (26.2.0)\n",
      "Requirement already satisfied: msgspec in /home/sylvia/anaconda3/envs/papillon/lib/python3.10/site-packages (from vllm>=0.6.3.post1->sglang[all]) (0.18.6)\n",
      "Requirement already satisfied: gguf==0.10.0 in /home/sylvia/anaconda3/envs/papillon/lib/python3.10/site-packages (from vllm>=0.6.3.post1->sglang[all]) (0.10.0)\n",
      "Requirement already satisfied: mistral-common>=1.5.0 in /home/sylvia/anaconda3/envs/papillon/lib/python3.10/site-packages (from mistral-common[opencv]>=1.5.0->vllm>=0.6.3.post1->sglang[all]) (1.5.1)\n",
      "Requirement already satisfied: pyyaml in /home/sylvia/anaconda3/envs/papillon/lib/python3.10/site-packages (from vllm>=0.6.3.post1->sglang[all]) (6.0.2)\n",
      "Requirement already satisfied: einops in /home/sylvia/anaconda3/envs/papillon/lib/python3.10/site-packages (from vllm>=0.6.3.post1->sglang[all]) (0.8.0)\n",
      "Requirement already satisfied: compressed-tensors==0.8.0 in /home/sylvia/anaconda3/envs/papillon/lib/python3.10/site-packages (from vllm>=0.6.3.post1->sglang[all]) (0.8.0)\n",
      "Requirement already satisfied: ray>=2.9 in /home/sylvia/anaconda3/envs/papillon/lib/python3.10/site-packages (from vllm>=0.6.3.post1->sglang[all]) (2.39.0)\n",
      "Requirement already satisfied: nvidia-ml-py>=12.560.30 in /home/sylvia/anaconda3/envs/papillon/lib/python3.10/site-packages (from vllm>=0.6.3.post1->sglang[all]) (12.560.30)\n",
      "Requirement already satisfied: torchvision==0.20.1 in /home/sylvia/anaconda3/envs/papillon/lib/python3.10/site-packages (from vllm>=0.6.3.post1->sglang[all]) (0.20.1)\n",
      "Requirement already satisfied: xformers==0.0.28.post3 in /home/sylvia/anaconda3/envs/papillon/lib/python3.10/site-packages (from vllm>=0.6.3.post1->sglang[all]) (0.0.28.post3)\n",
      "Requirement already satisfied: fastapi!=0.113.*,!=0.114.0,>=0.107.0 in /home/sylvia/anaconda3/envs/papillon/lib/python3.10/site-packages (from vllm>=0.6.3.post1->sglang[all]) (0.115.5)\n",
      "Requirement already satisfied: networkx in /home/sylvia/.local/lib/python3.10/site-packages (from torch->sglang[all]) (3.4.2)\n",
      "Requirement already satisfied: fsspec in /home/sylvia/.local/lib/python3.10/site-packages (from torch->sglang[all]) (2024.9.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/sylvia/.local/lib/python3.10/site-packages (from torch->sglang[all]) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/sylvia/.local/lib/python3.10/site-packages (from torch->sglang[all]) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/sylvia/.local/lib/python3.10/site-packages (from torch->sglang[all]) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/sylvia/.local/lib/python3.10/site-packages (from torch->sglang[all]) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/sylvia/.local/lib/python3.10/site-packages (from torch->sglang[all]) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/sylvia/.local/lib/python3.10/site-packages (from torch->sglang[all]) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/sylvia/.local/lib/python3.10/site-packages (from torch->sglang[all]) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/sylvia/.local/lib/python3.10/site-packages (from torch->sglang[all]) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/sylvia/.local/lib/python3.10/site-packages (from torch->sglang[all]) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/sylvia/.local/lib/python3.10/site-packages (from torch->sglang[all]) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/sylvia/.local/lib/python3.10/site-packages (from torch->sglang[all]) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/sylvia/.local/lib/python3.10/site-packages (from torch->sglang[all]) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /home/sylvia/.local/lib/python3.10/site-packages (from torch->sglang[all]) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/sylvia/.local/lib/python3.10/site-packages (from torch->sglang[all]) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/sylvia/.local/lib/python3.10/site-packages (from sympy==1.13.1->torch->sglang[all]) (1.3.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/sylvia/.local/lib/python3.10/site-packages (from datasets->dspy>=2.5.3->dspy-ai==2.5.41) (18.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/sylvia/.local/lib/python3.10/site-packages (from datasets->dspy>=2.5.3->dspy-ai==2.5.41) (0.3.8)\n",
      "Requirement already satisfied: xxhash in /home/sylvia/.local/lib/python3.10/site-packages (from datasets->dspy>=2.5.3->dspy-ai==2.5.41) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/sylvia/.local/lib/python3.10/site-packages (from datasets->dspy>=2.5.3->dspy-ai==2.5.41) (0.70.16)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in /home/sylvia/.local/lib/python3.10/site-packages (from datasets->dspy>=2.5.3->dspy-ai==2.5.41) (0.26.2)\n",
      "Requirement already satisfied: packaging in /home/sylvia/.local/lib/python3.10/site-packages (from datasets->dspy>=2.5.3->dspy-ai==2.5.41) (24.2)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /home/sylvia/.local/lib/python3.10/site-packages (from optuna->dspy>=2.5.3->dspy-ai==2.5.41) (1.14.0)\n",
      "Requirement already satisfied: colorlog in /home/sylvia/.local/lib/python3.10/site-packages (from optuna->dspy>=2.5.3->dspy-ai==2.5.41) (6.9.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in /home/sylvia/.local/lib/python3.10/site-packages (from optuna->dspy>=2.5.3->dspy-ai==2.5.41) (2.0.36)\n",
      "Collecting decord (from sglang[all])\n",
      "  Downloading decord-0.6.0-py3-none-manylinux2010_x86_64.whl.metadata (422 bytes)\n",
      "Collecting hf_transfer (from sglang[all])\n",
      "  Downloading hf_transfer-0.1.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: interegular in /home/sylvia/anaconda3/envs/papillon/lib/python3.10/site-packages (from sglang[all]) (0.3.3)\n",
      "Collecting orjson (from sglang[all])\n",
      "  Downloading orjson-3.10.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (41 kB)\n",
      "Collecting python-multipart (from sglang[all])\n",
      "  Downloading python_multipart-0.0.19-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting torchao (from sglang[all])\n",
      "  Downloading torchao-0.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: uvloop in /home/sylvia/anaconda3/envs/papillon/lib/python3.10/site-packages (from sglang[all]) (0.21.0)\n",
      "Collecting modelscope (from sglang[all])\n",
      "  Downloading modelscope-1.20.1-py3-none-any.whl.metadata (40 kB)\n",
      "Requirement already satisfied: executing>=1.2.0 in /home/sylvia/.local/lib/python3.10/site-packages (from stack-data->IPython->sglang[all]) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /home/sylvia/.local/lib/python3.10/site-packages (from stack-data->IPython->sglang[all]) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /home/sylvia/.local/lib/python3.10/site-packages (from stack-data->IPython->sglang[all]) (0.2.3)\n",
      "Requirement already satisfied: Mako in /home/sylvia/anaconda3/envs/papillon/lib/python3.10/site-packages (from alembic>=1.5.0->optuna->dspy>=2.5.3->dspy-ai==2.5.41) (1.3.6)\n",
      "Requirement already satisfied: starlette<0.42.0,>=0.40.0 in /home/sylvia/anaconda3/envs/papillon/lib/python3.10/site-packages (from fastapi!=0.113.*,!=0.114.0,>=0.107.0->vllm>=0.6.3.post1->sglang[all]) (0.41.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/sylvia/.local/lib/python3.10/site-packages (from aiohttp->litellm==1.51.0->dspy>=2.5.3->dspy-ai==2.5.41) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/sylvia/.local/lib/python3.10/site-packages (from aiohttp->litellm==1.51.0->dspy>=2.5.3->dspy-ai==2.5.41) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/sylvia/.local/lib/python3.10/site-packages (from aiohttp->litellm==1.51.0->dspy>=2.5.3->dspy-ai==2.5.41) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/sylvia/.local/lib/python3.10/site-packages (from aiohttp->litellm==1.51.0->dspy>=2.5.3->dspy-ai==2.5.41) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/sylvia/.local/lib/python3.10/site-packages (from aiohttp->litellm==1.51.0->dspy>=2.5.3->dspy-ai==2.5.41) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/sylvia/.local/lib/python3.10/site-packages (from aiohttp->litellm==1.51.0->dspy>=2.5.3->dspy-ai==2.5.41) (0.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/sylvia/.local/lib/python3.10/site-packages (from aiohttp->litellm==1.51.0->dspy>=2.5.3->dspy-ai==2.5.41) (1.17.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /home/sylvia/.local/lib/python3.10/site-packages (from aiohttp->litellm==1.51.0->dspy>=2.5.3->dspy-ai==2.5.41) (5.0.1)\n",
      "Requirement already satisfied: zipp>=3.20 in /home/sylvia/.local/lib/python3.10/site-packages (from importlib-metadata>=6.8.0->litellm==1.51.0->dspy>=2.5.3->dspy-ai==2.5.41) (3.21.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/sylvia/anaconda3/envs/papillon/lib/python3.10/site-packages (from jinja2<4.0.0,>=3.1.2->litellm==1.51.0->dspy>=2.5.3->dspy-ai==2.5.41) (3.0.2)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/sylvia/.local/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm==1.51.0->dspy>=2.5.3->dspy-ai==2.5.41) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/sylvia/.local/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm==1.51.0->dspy>=2.5.3->dspy-ai==2.5.41) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/sylvia/.local/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm==1.51.0->dspy>=2.5.3->dspy-ai==2.5.41) (0.21.0)\n",
      "Requirement already satisfied: opencv-python-headless<5.0.0,>=4.0.0 in /home/sylvia/anaconda3/envs/papillon/lib/python3.10/site-packages (from mistral-common[opencv]>=1.5.0->vllm>=0.6.3.post1->sglang[all]) (4.10.0.84)\n",
      "Requirement already satisfied: lark in /home/sylvia/anaconda3/envs/papillon/lib/python3.10/site-packages (from outlines<0.1,>=0.0.43->vllm>=0.6.3.post1->sglang[all]) (1.2.2)\n",
      "Requirement already satisfied: nest-asyncio in /home/sylvia/anaconda3/envs/papillon/lib/python3.10/site-packages (from outlines<0.1,>=0.0.43->vllm>=0.6.3.post1->sglang[all]) (1.6.0)\n",
      "Requirement already satisfied: cloudpickle in /home/sylvia/anaconda3/envs/papillon/lib/python3.10/site-packages (from outlines<0.1,>=0.0.43->vllm>=0.6.3.post1->sglang[all]) (3.1.0)\n",
      "Requirement already satisfied: numba in /home/sylvia/anaconda3/envs/papillon/lib/python3.10/site-packages (from outlines<0.1,>=0.0.43->vllm>=0.6.3.post1->sglang[all]) (0.60.0)\n",
      "Requirement already satisfied: pycountry in /home/sylvia/anaconda3/envs/papillon/lib/python3.10/site-packages (from outlines<0.1,>=0.0.43->vllm>=0.6.3.post1->sglang[all]) (24.6.1)\n",
      "Requirement already satisfied: pyairports in /home/sylvia/anaconda3/envs/papillon/lib/python3.10/site-packages (from outlines<0.1,>=0.0.43->vllm>=0.6.3.post1->sglang[all]) (2.1.1)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /home/sylvia/anaconda3/envs/papillon/lib/python3.10/site-packages (from ray>=2.9->vllm>=0.6.3.post1->sglang[all]) (1.1.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/sylvia/.local/lib/python3.10/site-packages (from sqlalchemy>=1.4.2->optuna->dspy>=2.5.3->dspy-ai==2.5.41) (3.1.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/sylvia/anaconda3/envs/papillon/lib/python3.10/site-packages (from transformers>=4.45.2->vllm>=0.6.3.post1->sglang[all]) (0.4.5)\n",
      "Requirement already satisfied: httptools>=0.6.3 in /home/sylvia/anaconda3/envs/papillon/lib/python3.10/site-packages (from uvicorn[standard]->vllm>=0.6.3.post1->sglang[all]) (0.6.4)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /home/sylvia/anaconda3/envs/papillon/lib/python3.10/site-packages (from uvicorn[standard]->vllm>=0.6.3.post1->sglang[all]) (0.24.0)\n",
      "Requirement already satisfied: websockets>=10.4 in /home/sylvia/anaconda3/envs/papillon/lib/python3.10/site-packages (from uvicorn[standard]->vllm>=0.6.3.post1->sglang[all]) (14.1)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /home/sylvia/anaconda3/envs/papillon/lib/python3.10/site-packages (from numba->outlines<0.1,>=0.0.43->vllm>=0.6.3.post1->sglang[all]) (0.43.0)\n",
      "Downloading dspy_ai-2.5.41-py3-none-any.whl (339 kB)\n",
      "Downloading anthropic-0.40.0-py3-none-any.whl (199 kB)\n",
      "Downloading decord-0.6.0-py3-none-manylinux2010_x86_64.whl (13.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.6/13.6 MB\u001b[0m \u001b[31m52.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading hf_transfer-0.1.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m80.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading modelscope-1.20.1-py3-none-any.whl (5.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m72.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading orjson-3.10.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (131 kB)\n",
      "Downloading python_multipart-0.0.19-py3-none-any.whl (24 kB)\n",
      "Downloading torchao-0.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: torchao, python-multipart, orjson, hf_transfer, decord, modelscope, anthropic, dspy-ai\n",
      "  Attempting uninstall: dspy-ai\n",
      "    Found existing installation: dspy-ai 2.5.35\n",
      "    Uninstalling dspy-ai-2.5.35:\n",
      "      Successfully uninstalled dspy-ai-2.5.35\n",
      "Successfully installed anthropic-0.40.0 decord-0.6.0 dspy-ai-2.5.41 hf_transfer-0.1.8 modelscope-1.20.1 orjson-3.10.12 python-multipart-0.0.19 torchao-0.6.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install dspy-ai==2.5.41 openai pandas sglang[all]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Launch Llama-3.1-8B-Instruct\n",
    "We will host this model using SGLang. If you have the model hosted somewhere else, that should also be okay, you can just adjust the `local_lm` variable accordingly in the following sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install flashinfer -i https://flashinfer.ai/whl/cu121/torch2.4/ \n",
    "\n",
    "PORT_NUMBER = 7501 # You can change the port number here\n",
    "\n",
    "!CUDA_VISIBLE_DEVICES=0 python -m sglang.launch_server --port $PORT_NUMBER --model-path meta-llama/Llama-3.1-8B-Instruct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Local LM and Remote LLM\n",
    "The Local LM would correspond to the trusted (but usually weaker) model. The Local LM should ideally be the only component of the pipeline that manages your private information. The Remote LM would correspond to the untrusted (but usually more potent) model. The goal of the PAPILLON pipeline is to produce high-quality outputs while leaking as little of your private information as possible to the Remote LM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"<YOUR_API_KEY>\"\n",
    "\n",
    "local_lm = dspy.LM('openai/default', api_base=f\"http://127.0.0.1:{PORT_NUMBER}/v1\", api_key=\"\", max_tokens=4000)\n",
    "dspy.configure(lm=local_lm)\n",
    "\n",
    "openai_lm = dspy.OpenAI(model=\"gpt-4o-mini\", max_tokens=4000)\n",
    "\n",
    "openai_gpt4o = dspy.OpenAI(model=\"gpt-4o-mini\", max_tokens=4000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the PAPILLON DSPy Module\n",
    "We will now define the Prompt Creator and Information Aggregator modules according to the diagram earlier in this notebook. \n",
    "\n",
    "After defining the module, we can then optimize the prompts for these modules using the MIPRO v2 DSPy prompt optimizer, so that you can keep creating new PAPILLON pipelines for your specific needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CreateOnePrompt(dspy.Signature):\n",
    "    \"\"\"\n",
    "    You are a helpful assistant that is very mindful of user privacy. You have access to a powerful large language model that you can query. Given a user request, create a prompt for your large language model that preserves user privacy, so that this model can help you complete the user request. Provide the prompt directly without any preamble. DO NOT COMPLETE THE USER QUERY, ONLY GENERATE A PROMPT.\n",
    "    \"\"\"\n",
    "    userQuery = dspy.InputField(desc=\"The user's request to be fulfilled.\")\n",
    "    createdPrompt = dspy.OutputField()\n",
    "\n",
    "class InfoAggregator(dspy.Signature):\n",
    "    \"\"\"\n",
    "    You are a helpful assistant. Respond to queries from the user.\n",
    "    \"\"\"\n",
    "\n",
    "    userQuery = dspy.InputField(desc=\"The user's request to be fulfilled.\")\n",
    "    modelExampleResponses = dspy.InputField(desc=\"You have the following information from a better language model responding to related query or queries. Complete the user query by referencing this information. Only you have access to this information.\", format=lambda s: f'======\\n\\n{s.strip()}\\n\\n======')\n",
    "    finalOutput = dspy.OutputField()\n",
    "\n",
    "\n",
    "\n",
    "class PrivacyOnePrompter(dspy.Module):\n",
    "    def __init__(self, trusted_model, untrusted_model):\n",
    "        super().__init__()\n",
    "        self.prompt_creater = dspy.ChainOfThought(CreateOnePrompt)\n",
    "        self.info_aggregator = dspy.Predict(InfoAggregator)\n",
    "        self.trusted_model = trusted_model\n",
    "        dspy.configure(lm=self.trusted_model)\n",
    "        self.untrusted_model = untrusted_model\n",
    "        \n",
    "    \n",
    "    def forward(self, user_query):\n",
    "        try:\n",
    "            prompt = self.prompt_creater(userQuery=user_query)\n",
    "        except ValueError:\n",
    "            return dspy.Prediction(\n",
    "                prompt=\"\",\n",
    "                output=\"\",\n",
    "                gptResponse=\"\"\n",
    "            )\n",
    "        try:\n",
    "            response = self.untrusted_model(prompt.createdPrompt)[0]\n",
    "        except ValueError:\n",
    "            return dspy.Prediction(\n",
    "                prompt=\"\",\n",
    "                output=\"\",\n",
    "                gptResponse=\"\"\n",
    "            )\n",
    "        try:\n",
    "            final_output = self.info_aggregator(userQuery=user_query, modelExampleResponses=response)\n",
    "        except ValueError:\n",
    "            return dspy.Prediction(\n",
    "                prompt=\"\",\n",
    "                output=\"\",\n",
    "                gptResponse=response\n",
    "            )\n",
    "        return dspy.Prediction(\n",
    "            prompt=prompt.createdPrompt,\n",
    "            output=final_output.finalOutput,\n",
    "            gptResponse=response\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize Your PAPILLON Pipeline\n",
    "#### Let's First Load Some Data\n",
    "\n",
    "In our paper, we proposed the PUPA benchmark, available both on Huggingface (TBD) and in this repository (`pupa/*.csv`).\n",
    "\n",
    "The PUPA benchmark contains user-assistant interactions where the user divulges personally identifiable information (PII) in the [WildChat](https://arxiv.org/abs/2405.01470) dataset. We use annotation schemas detailed in the [Trust No Bot](https://arxiv.org/abs/2407.11438) paper to determine whether an interaction contains private information of specific types. PUPA consists of two parts:\n",
    "1. `PUPA-TNB` is data derived from the original annotations from the Trust No Bot paper.\n",
    "2. `PUPA-New` is data derived from the rest of the WildChat dataset that is not annotated in the Trust No Bot paper.\n",
    "\n",
    "We will use PUPA-New to optimize our PAPILLON program and for evaluation before and after the optimization. In our paper, we used PUPA-TNB for standardized evaluation across different models, but we are just using PUPA-New here for demonstration purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL USER QUERY:\n",
      "Rachel Zheng is a clerk in the Administrative Department of H&R Technology. When she returns to the office, she finds a telephone message left by Johnny Bay, a manager of her department. In five days, Johnny will fly with the vice-president to the Univeristy of Westminster in order to attend a meeting. Johnny asks Rachel to book a hotel for them in Westminster. She needs to write an email to Johnny to explain her suggestions before booking. 请将以上句子翻译成中文\n",
      "PII UNITS:\n",
      "rachel||johnny||univeristy of westminster||westminster||johnny bay||rachel zheng||h&r technology\n",
      "TARGET RESPONSE FROM PAPILLON:\n",
      "Rachel Zheng 是 H&R Technology 行政部门的职员。当她回到办公室时，发现办公室留了一个电话留言，留言是由她所在部门的经理 Johnny Bay 留的。Johnny 将在五天后和副总裁一起飞往威斯敏斯特大学参加会议。Johnny 请求 Rachel 为他们在威斯敏斯特预订酒店。在预订之前，她需要给 Johnny 发送一封邮件解释她的建议。\n",
      "====\n",
      "ORIGINAL USER QUERY:\n",
      "Please describe the job knowledge requirements of the International Advising Assistant position at University; the amount of information and understanding necessary to perform the job duties. For an existing role, please describe how this job knowledge requirements have changed.\n",
      "PII UNITS:\n",
      "university\n",
      "TARGET RESPONSE FROM PAPILLON:\n",
      "The International Advising Assistant position at a University requires a significant amount of job knowledge and understanding to effectively perform the duties. This role involves assisting international students with various tasks related to their academic and personal needs. The job knowledge requirements include a thorough understanding of the university's policies and procedures related to international students. This includes knowledge of admission requirements, registration processes, and academic policies specific to international students. The International Advising Assistant must also be familiar with visa regulations and immigration requirements to provide accurate information and guidance to students. Additionally, a strong understanding of the educational systems and practices in different countries is essential. This knowledge helps the adviser provide accurate assessments of course equivalencies, transfer credits, and academic progress for international students. As the role of an International Advising Assistant is constantly evolving, the job knowledge requirements have undergone some changes. With the increasing number of international students at universities, there is a greater need for advisers to be familiar with cultural differences and the challenges faced by international students. As a result, the job knowledge requirements now include a broader understanding of cross-cultural communication, support services, and resources available to international students. Furthermore, the growing complexity of visa regulations and immigration policies has necessitated an updated understanding of these areas. International Advising Assistants now need to stay up-to-date with any changes or updates in visa regulations to provide accurate and timely information to students. In addition, technological advancements have also impacted the job knowledge requirements. The current role of an International Advising Assistant involves utilizing various software and systems to manage and process student information, including international student tracking systems and student relationship management platforms. Therefore, a working knowledge of these technological tools is now essential for efficiently performing job duties. Overall, the job knowledge requirements of the International Advising Assistant position have expanded to encompass a deeper understanding of cross-cultural communication, support services, visa regulations, and technology. Keeping up with these evolving requirements ensures that the adviser can effectively assist and support international students throughout their academic journey.\n",
      "====\n",
      "ORIGINAL USER QUERY:\n",
      "i want to write a letter to the royal college of emergency medicine explaining the war situation in Sudan\n",
      "PII UNITS:\n",
      "Sudan\n",
      "TARGET RESPONSE FROM PAPILLON:\n",
      "[Your Name] [Your Address] [City, State, ZIP Code] [Email Address] [Date] Royal College of Emergency Medicine Victoria House 35-37 Victoria Street London SW1H 0EU Dear Sir/Madam, Subject: Urgent Concerns about the War Situation in Sudan I hope this letter finds you well. I am writing to bring your attention to the escalating war situation in Sudan, and to highlight the urgent need for emergency medical assistance in the affected regions. As you are aware, Sudan has been grappling with a devastating civil conflict for several years. The conflict has resulted in widespread violence, displacement, and a severe humanitarian crisis. Civilians, including women, children, and the elderly, are bearing the brunt of this conflict, with numerous casualties and a significant lack of access to basic medical care. The war has severely impacted the healthcare infrastructure in Sudan, leaving hospitals and clinics in ruins and exacerbating the already fragile state of emergency medical services. Emergency medical professionals are in short supply, facing overwhelming numbers of patients and limited resources to treat injuries and illnesses resulting from the conflict. Given the Royal College of Emergency Medicine's commitment to promoting compassionate and effective emergency care worldwide, I kindly request your assistance in raising awareness about the urgent medical needs in Sudan. The situation warrants international attention and support to alleviate the suffering and address the medical needs of the affected population. I urge the Royal College of Emergency Medicine to: 1. Advocate for increased international humanitarian aid specifically allocated to emergency medical services in Sudan. 2. Engage with relevant organizations and stakeholders to raise awareness about the dire situation in Sudan and encourage coordinated efforts towards addressing the healthcare needs of the affected population. 3. Explore potential collaborations with local medical organizations or charities already on the ground in Sudan to provide much-needed training, support, and resources to emergency medical professionals. I believe that by taking concerted action, we can make a significant difference in providing urgent medical assistance to the people of Sudan. Time is of the essence as lives are being lost due to the lack of proper medical care. The Royal College of Emergency Medicine has a unique opportunity to demonstrate its commitment to emergency care beyond borders and contribute to saving lives in Sudan. Thank you for your attention to this pressing matter. I look forward to hearing from you on any actions or initiatives that the Royal College of Emergency Medicine may undertake to address the war situation in Sudan. Yours sincerely, [Your Name]\n",
      "====\n",
      "ORIGINAL USER QUERY:\n",
      "critically analyze the film You Shall Not Kill by Krzysztof Kieślowski and express an opinion\n",
      "PII UNITS:\n",
      "krzysztof kieślowski\n",
      "TARGET RESPONSE FROM PAPILLON:\n",
      "As an AI language model, I am not programmed to have opinions, beliefs or preferences, but I can provide a critical analysis of the film You Shall Not Kill by Krzysztof Kieślowski. You Shall Not Kill is a powerful film by Krzysztof Kieślowski, which explores the ethical and emotional complexities of capital punishment. The film follows a man who becomes the executioner for the state, but gradually begins to question the morality of state-sanctioned killing. The film is expertly crafted, with Kieślowski's signature visual style and attention to detail. The use of color, lighting, and composition all contribute to the film's somber, atmospheric tone. The performances by the actors, especially the lead character, are nuanced and sensitive, conveying the inner struggles and conflicts of the protagonist. The film raises important philosophical and moral questions, such as whether killing can ever be justified, what are the implications of state-sanctioned killing, and whether murderers retain their dignity even in death. The film forces the audience to reflect on their own beliefs and values regarding capital punishment. Overall, You Shall Not Kill is a powerful and thought-provoking film that invites viewers to contemplate the ethics of capital punishment. Kieślowski has created a work of art that is both emotionally affecting and intellectually challenging, and it remains relevant and timely even today.\n",
      "====\n"
     ]
    }
   ],
   "source": [
    "# Let's first take a look at some data examples\n",
    "import pandas\n",
    "\n",
    "pupa_tnb = pandas.read_csv(\"pupa/PUPA_TNB.csv\")\n",
    "\n",
    "for i, row in pupa_tnb.iterrows():\n",
    "    if i > 3:\n",
    "        break\n",
    "    print(\"ORIGINAL USER QUERY:\")\n",
    "    print(row[\"user_query\"])\n",
    "    print(\"PII UNITS:\")\n",
    "    print(row[\"pii_units\"])\n",
    "    print(\"TARGET RESPONSE FROM PAPILLON:\")\n",
    "    print(row[\"target_response\"])\n",
    "    print(\"====\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Processing function\n",
    "from dspy import Example\n",
    "\n",
    "def synthesize_tvt(data_file):\n",
    "    df = pandas.read_csv(data_file, index_col=False)\n",
    "    train, val, test = [], [], []\n",
    "    for i, row in df.iterrows():\n",
    "        if pandas.isna(row[\"pii_units\"]) or not isinstance(row[\"pii_units\"], str) or len(row[\"pii_units\"]) == 0:\n",
    "            continue\n",
    "        new_dp = Example({\"target_response\": row[\"target_response\"],\n",
    "                          \"user_query\": row[\"user_query\"],\n",
    "                          \"pii_str\": row[\"pii_units\"]}).with_inputs(\"user_query\")\n",
    "        if i < 150:\n",
    "            train.append(new_dp)\n",
    "        elif 150 <= i < 300:\n",
    "            val.append(new_dp)\n",
    "        else:\n",
    "            test.append(new_dp)\n",
    "    return train, val, test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of the optimization process is to:\n",
    "1. Make sure the PAPILLON responses are at least on par with the `target_response`\n",
    "2. Leak as few `pii_units` to the Remote LLM as possible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the LLM Judge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JudgeQuality(dspy.Signature):\n",
    "    \"\"\"You are comparing the quality of two responses, given a user query. Is response A at least as good as response B? Respond with yes or no.\"\"\"\n",
    "\n",
    "    user_query = dspy.InputField(desc=\"The user's request to be fulfilled.\")\n",
    "    response_A = dspy.InputField()\n",
    "    response_B = dspy.InputField()\n",
    "    output = dspy.OutputField()\n",
    "\n",
    "class JudgeLeakage(dspy.Signature):\n",
    "    \"\"\"Determine whether a piece of information is present in the prompt given. Respond with yes or no.\"\"\"\n",
    "\n",
    "    information_piece = dspy.InputField(desc=\"The piece of information that we wish to check. If this piece of information is a celebrity name, respond with no.\")\n",
    "    prompt = dspy.InputField()\n",
    "    output = dspy.OutputField()\n",
    "\n",
    "class JudgePromptQual(dspy.Signature):\n",
    "    \"\"\"Determine whether a piece of text is a valid prompt for a language model. Respond with yes or no.\"\"\"\n",
    "    prompt_input = dspy.InputField()\n",
    "    output = dspy.OutputField()\n",
    "\n",
    "\n",
    "class LLMJudge(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.quality_judge = dspy.ChainOfThought(JudgeQuality)\n",
    "        self.fact_checker = dspy.Predict(JudgeLeakage)\n",
    "        self.prompt_qual = dspy.ChainOfThought(JudgePromptQual)\n",
    "\n",
    "    def forward(self, user_query, og_resp, new_resp=None, updated_query=None, pii_str=None):\n",
    "        if new_resp:\n",
    "            answer = self.quality_judge(user_query=user_query, response_A=new_resp, response_B=og_resp)\n",
    "            judgment_1 = int((answer.output.lower()).startswith(\"yes\"))\n",
    "            answer = self.quality_judge(user_query=user_query, response_A=og_resp, response_B=new_resp)\n",
    "            judgment_2 = int((answer.output.lower()).startswith(\"yes\"))\n",
    "            judgment = process_scores(judgment_1, judgment_2)\n",
    "        else:\n",
    "            judgment = -1\n",
    "        if updated_query:\n",
    "            if isinstance(pii_str, str):\n",
    "                # The pii_str field must be separated by ||\n",
    "                all_ppi_pieces = set(pii_str.split(\"||\"))\n",
    "                ppi_score = 0\n",
    "                for p in all_ppi_pieces:\n",
    "                    answer = self.fact_checker(information_piece=p, prompt=updated_query)\n",
    "                    ppi_score += int((answer.output.lower()).startswith(\"yes\"))\n",
    "            else:\n",
    "                ppi_score = -1\n",
    "            ans = self.prompt_qual(prompt_input=updated_query)\n",
    "            prompt_score = int((ans.output.lower()).startswith(\"yes\"))\n",
    "        else:\n",
    "            ppi_score = -1\n",
    "            prompt_score = -1\n",
    "        \n",
    "        return dspy.Prediction(\n",
    "            quality=judgment,\n",
    "            leakage=ppi_score,\n",
    "            prompt=prompt_score\n",
    "        )\n",
    "\n",
    "\n",
    "def process_scores(s1, s2):\n",
    "    # If the model thinks A > B and B > A (or the other way around but the model is not consistent)\n",
    "    # We would assume that the two items are equal in quality\n",
    "    # You can adjust the metric accordingly if needed\n",
    "    if s1 == s2:\n",
    "        return 1\n",
    "    return s1\n",
    "\n",
    "llm_judge = LLMJudge()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the Metric\n",
    "This will guide the prompt optimization process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric(gold, pred, trace=None):\n",
    "    og_model_output, og_user_query, og_pii = gold.target_response, gold.user_query, gold.pii_str\n",
    "    pred_prompt, pred_out = pred.prompt, pred.output\n",
    "    if len(pred_prompt) == 0:\n",
    "        return 0\n",
    "    with dspy.context(lm=openai_gpt4o):\n",
    "        score_dict = llm_judge(user_query=og_user_query, new_resp=pred_out, og_resp=og_model_output,\n",
    "                                            updated_query=pred_prompt, pii_str=og_pii)       \n",
    "        final_quality_score = score_dict.quality\n",
    "        leakage_sc = score_dict.leakage\n",
    "        prompt_sc = score_dict.prompt\n",
    "        try:\n",
    "            assert leakage_sc != -1\n",
    "        except AssertionError:\n",
    "            return 0\n",
    "    # Want to maximize quality and minimize percentage of leakage\n",
    "    final_total_score = (final_quality_score - leakage_sc / len(set(og_pii.split(\"||\"))) + prompt_sc) / 2\n",
    "    if trace is not None: return final_total_score >= 1\n",
    "    return final_total_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimize with MIPRO v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dspy.evaluate.evaluate import Evaluate\n",
    "from dspy.teleprompt import MIPROv2\n",
    "import json\n",
    "\n",
    "DATA_PATH = \"pupa/PUPA_New.csv\"\n",
    "# Where you want to store the optimized prompts\n",
    "PROMPT_OUTPUT_FILE = \"output_prompt.json\" \n",
    "\n",
    "train, val, test = synthesize_tvt(DATA_PATH)\n",
    "zeroshot = PrivacyOnePrompter(local_lm, openai_lm)\n",
    "INCOMPLIANCE = 0\n",
    "evaluate = Evaluate(metric=metric, devset=val, num_threads=8, display_progress=True, display_table=5, max_errors=100)\n",
    "try:\n",
    "    eval_score = evaluate(zeroshot)\n",
    "except Exception as e:\n",
    "    INCOMPLIANCE += 1\n",
    "eval_scores = {}\n",
    "eval_scores.update({\"before_optimization\": eval_score})\n",
    "print(eval_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    teleprompter = MIPROv2(prompt_model=openai_lm, task_model=local_lm, metric=metric, num_candidates=10, init_temperature=1.0)\n",
    "    kwargs = dict(num_threads=8, display_progress=True, display_table=0)\n",
    "    compiled_prompt_opt = teleprompter.compile(zeroshot, trainset=train, num_batches=200, max_bootstrapped_demos=0, max_labeled_demos=0, eval_kwargs=kwargs)\n",
    "    compiled_prompt_opt.save(PROMPT_OUTPUT_FILE)\n",
    "except ValueError as e:\n",
    "    print(e)\n",
    "    local_lm.inspect_history()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    eval_score = evaluate(compiled_prompt_opt, devset=val, **kwargs)\n",
    "    print(eval_score)\n",
    "    eval_scores.update({\"after_optimization\": eval_score})\n",
    "    \n",
    "except ValueError as e:\n",
    "    print(e)\n",
    "    local_lm.inspect_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EVAL_FILE = PROMPT_OUTPUT_FILE.replace(\".json\", \"_eval_socres.json\")\n",
    "json.dump(eval_scores, open(EVAL_FILE, \"w+\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying Your Optimized PAPILLON Module\n",
    "\n",
    "You have finished optimizing your PAPILLON module! Huzzah!! Now you can just load the newly optimized prompt and use it on user queries similar to those in PUPA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "priv_prompt = PrivacyOnePrompter(local_lm, openai_lm)\n",
    "    \n",
    "priv_prompt.load(PROMPT_OUTPUT_FILE)\n",
    "\n",
    "while True:\n",
    "    user_query = input(\"Your Query > \")\n",
    "    pred = priv_prompt(user_query)\n",
    "    print(\"PAPILLON PROMPT > \", pred.prompt)\n",
    "    print(\"PAPILLON OUTPUT > \", pred.output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "papillon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
